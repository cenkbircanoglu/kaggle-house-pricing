{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'rankdata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4c36d9b4aff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_search\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mDaskGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/udacity/lib/python3.6/site-packages/dklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDaskGridSearchCV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDaskRandomizedSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/udacity/lib/python3.6/site-packages/dklearn/model_selection.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_builder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/udacity/lib/python3.6/site-packages/dklearn/_builder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeatureUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msafe_indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrankdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaskedArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m from sklearn.utils.validation import (_num_samples, check_consistent_length,\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'rankdata'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from scipy.special import boxcox1p\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from rmsle import rmsle, rmsle_cv\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from stacking_average_models import StackingAveragedModels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, Normalizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_red = False\n",
    "imput = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\", index_col=False)\n",
    "test_data = pd.read_csv(\"data/test.csv\", index_col=False)\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_id = train_data[\"Id\"]\n",
    "te_id = test_data[\"Id\"]\n",
    "tr_y = np.log1p(train_data[\"SalePrice\"])\n",
    "#te_y = test_data[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(\"Id\", axis = 1, inplace = True)\n",
    "test_data.drop(\"Id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_values = {}\n",
    "for column in train_data.columns:\n",
    "    distinct_values[column]= train_data[column].nunique()\n",
    "print(distinct_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train_data.shape[0]\n",
    "ntest = test_data.shape[0]\n",
    "data = pd.concat((train_data, test_data)).reset_index(drop=True)\n",
    "data.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_na = (data.isnull().sum() / len(data)) * 100\n",
    "data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
    "missing_data.plot(kind=\"barh\",figsize=(6,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"PoolQC\"] = data[\"PoolQC\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"MiscFeature\"] = data[\"MiscFeature\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Alley\"] = data[\"Alley\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Fence\"] = data[\"Fence\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"FireplaceQu\"] = data[\"FireplaceQu\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"LotFrontage\"] = data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "    data[col] = data[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    data[col] = data[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "    data[col] = data[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    data[col] = data[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"MasVnrType\"] = data[\"MasVnrType\"].fillna(\"None\")\n",
    "data[\"MasVnrArea\"] = data[\"MasVnrArea\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MSZoning'] = data['MSZoning'].fillna(data['MSZoning'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Utilities'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Functional\"] = data[\"Functional\"].fillna(\"Typ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Electrical'] = data['Electrical'].fillna(data['Electrical'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['KitchenQual'] = data['KitchenQual'].fillna(data['KitchenQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Exterior1st'] = data['Exterior1st'].fillna(data['Exterior1st'].mode()[0])\n",
    "data['Exterior2nd'] = data['Exterior2nd'].fillna(data['Exterior2nd'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SaleType'] = data['SaleType'].fillna(data['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MSSubClass'] = data['MSSubClass'].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check remaining missing values if any \n",
    "data_na = (data.isnull().sum() / len(data)) * 100\n",
    "data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSSubClass=The building class\n",
    "data['MSSubClass'] = data['MSSubClass'].apply(str)\n",
    "\n",
    "#Changing OverallCond into a categorical variable\n",
    "data['OverallCond'] = data['OverallCond'].astype(str)\n",
    "\n",
    "#Year and month sold are transformed into categorical features.\n",
    "data['YrSold'] = data['YrSold'].astype(str)\n",
    "data['MoSold'] = data['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(data[c].values)) \n",
    "    data[c] = lbl.transform(list(data[c].values))\n",
    "print('Shape all_data: {}'.format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TotalSF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = data.dtypes[data.dtypes != \"object\"].index\n",
    "\n",
    "skewed_feats = data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    data[feat] = boxcox1p(data[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data = pd.get_dummies(data)\n",
    "tr_df = dummy_data[:ntrain]\n",
    "te_df = dummy_data[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_X = tr_df.values\n",
    "te_X = te_df.values\n",
    "tr_X.shape, te_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if imput:\n",
    "    my_imputer = Imputer()\n",
    "    tr_X = my_imputer.fit_transform(tr_X)\n",
    "    tr_X = StandardScaler().fit_transform(tr_X)\n",
    "    tr_X = Normalizer().fit_transform(tr_X)\n",
    "    te_X = my_imputer.fit_transform(te_X)\n",
    "    te_X = StandardScaler().fit_transform(te_X)\n",
    "    te_X = Normalizer().fit_transform(te_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dim_red:\n",
    "    pca = PCA(n_components=32)\n",
    "    pca = pca.fit(tr_X, tr_X)\n",
    "    tr_X = pca.transform(tr_X)\n",
    "    te_X = pca.transform(te_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'SalePrice' in list(tr_df):\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(MLPRegressor(random_state=9, max_iter=100000),{\n",
    "    \"activation\":[\"tanh\",\"relu\",\"logistic\",\"identity\"],\n",
    "    \"solver\" : [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    \"learning_rate\":[\"adaptive\"],\n",
    "    \"hidden_layer_sizes\":[(i,) for i in range(1,100,4)]\n",
    "}, verbose=1)\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/mlp_1_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(MLPRegressor(random_state=9, max_iter=100000),{\n",
    "    \"activation\":[\"tanh\",\"relu\",\"logistic\",\"identity\"],\n",
    "    \"solver\" : [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    \"learning_rate\":[\"adaptive\"],\n",
    "    \"hidden_layer_sizes\":[(32,i) for i in range(1,24,4)]\n",
    "}, verbose=1)\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/mlp_2_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(SVR(),{\n",
    "    \"kernel\":[\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"C\" : [1e3, 1e4, 1e5, 1e2,1],\n",
    "    \"epsilon\":[0.1,0.2,0.3,0.4,0.01,0.05,0.001],\n",
    "    \"degree\":[1,2,3,4,5]\n",
    "}, verbose=1)\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/svr_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(RandomForestRegressor(random_state=9),{\n",
    "    \"max_depth\":[i for i in range(1,16,1)]\n",
    "}, verbose=1)\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/random_forest_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.ARDRegression()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/ard_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.BayesianRidge()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/bayesian_ridge_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.ElasticNet(random_state=9)\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/elastic_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.HuberRegressor()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/huber_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Lars()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/lars_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Lasso()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/lasso_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LassoLars()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/lasso_lars_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LassoLarsIC()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/lasso_lars_ic_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LinearRegression(normalize=True, n_jobs=-1)\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/linear_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.PassiveAggressiveRegressor()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/par_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.RANSACRegressor()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/ransac_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/ridge_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.SGDRegressor()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/sgd_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.TheilSenRegressor()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/theil_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingRegressor()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/gradient_boosting_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "\n",
    "score = rmsle_cv(ENet, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "\n",
    "score = rmsle_cv(KRR, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "\n",
    "score = rmsle_cv(lasso, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "score = rmsle_cv(GBoost, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "stacked_averaged_models.fit(tr_X, tr_y)\n",
    "tr_pred = stacked_averaged_models.predict(tr_X)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(te_X))\n",
    "\n",
    "print(rmsle(tr_y, tr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "model_xgb.fit(tr_X, tr_y)\n",
    "xgb_pred = np.expm1(model_xgb.predict(te_X))\n",
    "\n",
    "score = rmsle_cv(model_xgb, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "model_lgb.fit(tr_X, tr_y)\n",
    "lgb_pred = np.expm1(model_lgb.predict(te_X))\n",
    "\n",
    "score = rmsle_cv(model_lgb, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = stacked_pred*0.7 + xgb_pred*0.15 + lgb_pred*0.15\n",
    "sub = pd.DataFrame()\n",
    "sub['Id'] = te_id\n",
    "sub['SalePrice'] = ensemble\n",
    "sub.to_csv('results/ensemble.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras.python.keras.layers import Dense\n",
    "from tensorflow.contrib.keras.python.keras.models import Sequential\n",
    "from tensorflow.contrib.keras.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "def create_model():\n",
    "    global input_dim\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(input_dim / 2), input_dim=input_dim, kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(int(input_dim / 4), kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(int(input_dim / 8), kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "input_dim = tr_X.shape[1]\n",
    "\n",
    "clf = KerasRegressor(build_fn=create_model, epochs=100, batch_size=5, verbose=0)\n",
    "clf.fit(tr_X, tr_y)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/dnn_regression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
