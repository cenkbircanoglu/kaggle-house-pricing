{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from scipy.special import boxcox1p\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from rmsle import rmsle, rmsle_cv\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from stacking_average_models import StackingAveragedModels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, Normalizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_red = False\n",
    "imput = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 81), (1459, 80))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\", index_col=False)\n",
    "test_data = pd.read_csv(\"data/test.csv\", index_col=False)\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>350</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>118000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "5   6          50       RL         85.0    14115   Pave   NaN      IR1   \n",
       "6   7          20       RL         75.0    10084   Pave   NaN      Reg   \n",
       "7   8          60       RL          NaN    10382   Pave   NaN      IR1   \n",
       "8   9          50       RM         51.0     6120   Pave   NaN      Reg   \n",
       "9  10         190       RL         50.0     7420   Pave   NaN      Reg   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "5         Lvl    AllPub    ...            0    NaN  MnPrv        Shed     700   \n",
       "6         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "7         Lvl    AllPub    ...            0    NaN    NaN        Shed     350   \n",
       "8         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "9         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "5     10   2009        WD         Normal     143000  \n",
       "6      8   2007        WD         Normal     307000  \n",
       "7     11   2009        WD         Normal     200000  \n",
       "8      4   2008        WD        Abnorml     129900  \n",
       "9      1   2008        WD         Normal     118000  \n",
       "\n",
       "[10 rows x 81 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_id = train_data[\"Id\"]\n",
    "te_id = test_data[\"Id\"]\n",
    "tr_y = np.log1p(train_data[\"SalePrice\"])\n",
    "#te_y = test_data[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(\"Id\", axis = 1, inplace = True)\n",
    "test_data.drop(\"Id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSSubClass': 15, 'MSZoning': 5, 'LotFrontage': 110, 'LotArea': 1073, 'Street': 2, 'Alley': 2, 'LotShape': 4, 'LandContour': 4, 'Utilities': 2, 'LotConfig': 5, 'LandSlope': 3, 'Neighborhood': 25, 'Condition1': 9, 'Condition2': 8, 'BldgType': 5, 'HouseStyle': 8, 'OverallQual': 10, 'OverallCond': 9, 'YearBuilt': 112, 'YearRemodAdd': 61, 'RoofStyle': 6, 'RoofMatl': 8, 'Exterior1st': 15, 'Exterior2nd': 16, 'MasVnrType': 4, 'MasVnrArea': 327, 'ExterQual': 4, 'ExterCond': 5, 'Foundation': 6, 'BsmtQual': 4, 'BsmtCond': 4, 'BsmtExposure': 4, 'BsmtFinType1': 6, 'BsmtFinSF1': 637, 'BsmtFinType2': 6, 'BsmtFinSF2': 144, 'BsmtUnfSF': 780, 'TotalBsmtSF': 721, 'Heating': 6, 'HeatingQC': 5, 'CentralAir': 2, 'Electrical': 5, '1stFlrSF': 753, '2ndFlrSF': 417, 'LowQualFinSF': 24, 'GrLivArea': 861, 'BsmtFullBath': 4, 'BsmtHalfBath': 3, 'FullBath': 4, 'HalfBath': 3, 'BedroomAbvGr': 8, 'KitchenAbvGr': 4, 'KitchenQual': 4, 'TotRmsAbvGrd': 12, 'Functional': 7, 'Fireplaces': 4, 'FireplaceQu': 5, 'GarageType': 6, 'GarageYrBlt': 97, 'GarageFinish': 3, 'GarageCars': 5, 'GarageArea': 441, 'GarageQual': 5, 'GarageCond': 5, 'PavedDrive': 3, 'WoodDeckSF': 274, 'OpenPorchSF': 202, 'EnclosedPorch': 120, '3SsnPorch': 20, 'ScreenPorch': 76, 'PoolArea': 8, 'PoolQC': 3, 'Fence': 4, 'MiscFeature': 4, 'MiscVal': 21, 'MoSold': 12, 'YrSold': 5, 'SaleType': 9, 'SaleCondition': 6, 'SalePrice': 663}\n"
     ]
    }
   ],
   "source": [
    "distinct_values = {}\n",
    "for column in train_data.columns:\n",
    "    distinct_values[column]= train_data[column].nunique()\n",
    "print(distinct_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train_data.shape[0]\n",
    "ntest = test_data.shape[0]\n",
    "data = pd.concat((train_data, test_data)).reset_index(drop=True)\n",
    "data.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x109b492e8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa8AAAHVCAYAAABG0nSmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103c5a908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_na = (data.isnull().sum() / len(data)) * 100\n",
    "data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
    "missing_data.plot(kind=\"barh\",figsize=(6,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"PoolQC\"] = data[\"PoolQC\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"MiscFeature\"] = data[\"MiscFeature\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Alley\"] = data[\"Alley\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Fence\"] = data[\"Fence\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"FireplaceQu\"] = data[\"FireplaceQu\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"LotFrontage\"] = data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "    data[col] = data[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    data[col] = data[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "    data[col] = data[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    data[col] = data[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"MasVnrType\"] = data[\"MasVnrType\"].fillna(\"None\")\n",
    "data[\"MasVnrArea\"] = data[\"MasVnrArea\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MSZoning'] = data['MSZoning'].fillna(data['MSZoning'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Utilities'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Functional\"] = data[\"Functional\"].fillna(\"Typ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Electrical'] = data['Electrical'].fillna(data['Electrical'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['KitchenQual'] = data['KitchenQual'].fillna(data['KitchenQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Exterior1st'] = data['Exterior1st'].fillna(data['Exterior1st'].mode()[0])\n",
    "data['Exterior2nd'] = data['Exterior2nd'].fillna(data['Exterior2nd'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SaleType'] = data['SaleType'].fillna(data['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MSSubClass'] = data['MSSubClass'].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Ratio]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check remaining missing values if any \n",
    "data_na = (data.isnull().sum() / len(data)) * 100\n",
    "data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSSubClass=The building class\n",
    "data['MSSubClass'] = data['MSSubClass'].apply(str)\n",
    "\n",
    "#Changing OverallCond into a categorical variable\n",
    "data['OverallCond'] = data['OverallCond'].astype(str)\n",
    "\n",
    "#Year and month sold are transformed into categorical features.\n",
    "data['YrSold'] = data['YrSold'].astype(str)\n",
    "data['MoSold'] = data['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape all_data: (2919, 78)\n"
     ]
    }
   ],
   "source": [
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(data[c].values)) \n",
    "    data[c] = lbl.transform(list(data[c].values))\n",
    "print('Shape all_data: {}'.format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TotalSF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew in numerical features: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>21.947195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>16.898328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>12.822431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>12.088761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>11.376065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandSlope</th>\n",
       "      <td>4.975157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>4.302254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>4.146143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>4.003891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>3.946694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Skew\n",
       "MiscVal        21.947195\n",
       "PoolArea       16.898328\n",
       "LotArea        12.822431\n",
       "LowQualFinSF   12.088761\n",
       "3SsnPorch      11.376065\n",
       "LandSlope       4.975157\n",
       "KitchenAbvGr    4.302254\n",
       "BsmtFinSF2      4.146143\n",
       "EnclosedPorch   4.003891\n",
       "ScreenPorch     3.946694"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_feats = data.dtypes[data.dtypes != \"object\"].index\n",
    "\n",
    "skewed_feats = data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 59 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    data[feat] = boxcox1p(data[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data = pd.get_dummies(data)\n",
    "tr_df = dummy_data[:ntrain]\n",
    "te_df = dummy_data[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 221)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 221), (1459, 221))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_X = tr_df.values\n",
    "te_X = te_df.values\n",
    "tr_X.shape, te_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if imput:\n",
    "    my_imputer = Imputer()\n",
    "    tr_X = my_imputer.fit_transform(tr_X)\n",
    "    tr_X = StandardScaler().fit_transform(tr_X)\n",
    "    tr_X = Normalizer().fit_transform(tr_X)\n",
    "    te_X = my_imputer.fit_transform(te_X)\n",
    "    te_X = StandardScaler().fit_transform(te_X)\n",
    "    te_X = Normalizer().fit_transform(te_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dim_red:\n",
    "    pca = PCA(n_components=32)\n",
    "    pca = pca.fit(tr_X, tr_X)\n",
    "    tr_X = pca.transform(tr_X)\n",
    "    te_X = pca.transform(te_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'SalePrice' in list(tr_df):\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.2325 (0.0164)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MLPRegressor(random_state=9, max_iter=100000)\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/mlp_1_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.1924 (0.0269)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MLPRegressor(random_state=9, hidden_layer_sizes=(32,8), max_iter=100000)\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/mlp_2_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1393 (0.0180)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVR(kernel='poly', C=1e3, degree=1)\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/svr_1_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1555 (0.0131)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVR(kernel='poly', C=1e3, degree=2)\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/svr_2_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1501 (0.0139)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVR(kernel='poly', C=1e3, degree=3)\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/svr_3_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1560 (0.0117)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVR()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/svr_4_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.2185 (0.0099)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/random_forest_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1336 (0.0171)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.ARDRegression()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/ard_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1290 (0.0147)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.BayesianRidge()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/bayesian_ridge_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.3770 (0.0176)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.ElasticNet(random_state=9)\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/elastic_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1308 (0.0170)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.HuberRegressor()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/huber_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 190 iterations, i.e. alpha=2.104e-05, with an active set of 181 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=1.654e-05, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=1.638e-05, with an active set of 184 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=1.257e-05, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=1.202e-05, with an active set of 190 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=1.503e-05, with an active set of 192 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 205 iterations, i.e. alpha=1.056e-05, with an active set of 193 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=9.779e-06, with an active set of 196 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=9.225e-06, with an active set of 196 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=8.688e-06, with an active set of 197 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=8.565e-06, with an active set of 197 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=7.663e-06, with an active set of 198 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=6.895e-06, with an active set of 198 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=5.953e-06, with an active set of 199 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=5.862e-06, with an active set of 199 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=1.818e-05, with an active set of 202 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=1.367e-05, with an active set of 202 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=9.139e-06, with an active set of 202 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=9.108e-06, with an active set of 202 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=8.103e-06, with an active set of 204 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=5.955e-06, with an active set of 204 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=5.886e-06, with an active set of 205 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=6.465e-06, with an active set of 206 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=6.350e-06, with an active set of 206 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=5.874e-06, with an active set of 206 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=5.680e-06, with an active set of 206 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=5.166e-06, with an active set of 206 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=4.762e-06, with an active set of 206 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=3.962e-06, with an active set of 206 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=4.011e-06, with an active set of 207 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=3.000e-06, with an active set of 207 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=2.848e-06, with an active set of 207 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=2.376e-06, with an active set of 207 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=2.233e-06, with an active set of 207 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=2.127e-06, with an active set of 207 regressors, and the smallest cholesky pivot element being 9.828e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=2.055e-06, with an active set of 207 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=1.933e-06, with an active set of 207 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=1.671e-06, with an active set of 207 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=1.453e-06, with an active set of 207 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=9.731e-07, with an active set of 207 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=9.606e-07, with an active set of 207 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=8.444e-07, with an active set of 207 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=6.306e-07, with an active set of 207 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in expm1\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=1.274e+00, with an active set of 188 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 251 iterations, i.e. alpha=1.181e+00, with an active set of 193 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.116e+00, with an active set of 194 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=1.121e+00, with an active set of 198 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=1.068e+00, with an active set of 198 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=8.459e-01, with an active set of 198 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=8.383e-01, with an active set of 198 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=8.226e-01, with an active set of 198 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=8.205e-01, with an active set of 198 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=8.356e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=7.165e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=7.098e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=7.027e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=6.730e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=5.562e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=4.955e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=4.488e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=4.347e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=3.283e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 9.003e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=2.785e-01, with an active set of 199 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=2.624e-01, with an active set of 200 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=2.367e-01, with an active set of 200 regressors, and the smallest cholesky pivot element being 8.878e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=1.678e-01, with an active set of 200 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=1.553e-01, with an active set of 200 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=1.532e-01, with an active set of 200 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=1.491e-01, with an active set of 200 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=1.294e-01, with an active set of 200 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=1.189e-01, with an active set of 200 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=5.328e-02, with an active set of 200 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=5.304e-02, with an active set of 200 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=5.302e-02, with an active set of 200 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=5.285e-02, with an active set of 200 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=5.279e-02, with an active set of 200 regressors, and the smallest cholesky pivot element being 7.068e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=4.520e-02, with an active set of 200 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=3.361e-02, with an active set of 200 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=3.169e-02, with an active set of 200 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=2.991e-02, with an active set of 200 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=2.875e-02, with an active set of 200 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.707e-02, with an active set of 144 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=7.663e-02, with an active set of 170 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=7.645e-02, with an active set of 170 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=7.276e-02, with an active set of 182 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 226 iterations, i.e. alpha=6.771e-02, with an active set of 183 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=7.788e-02, with an active set of 188 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=7.340e-02, with an active set of 189 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=7.789e-02, with an active set of 190 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=6.934e-02, with an active set of 192 regressors, and the smallest cholesky pivot element being 7.525e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=5.999e-02, with an active set of 192 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=5.346e-02, with an active set of 195 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=5.258e-02, with an active set of 195 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=5.044e-02, with an active set of 197 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=4.000e-02, with an active set of 198 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=3.718e-02, with an active set of 199 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=3.273e-02, with an active set of 199 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=2.983e-02, with an active set of 199 regressors, and the smallest cholesky pivot element being 7.224e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=2.968e-02, with an active set of 199 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=2.743e-02, with an active set of 199 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=1.713e-02, with an active set of 199 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=1.665e-02, with an active set of 199 regressors, and the smallest cholesky pivot element being 7.376e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=1.304e-02, with an active set of 199 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.244e-02, with an active set of 200 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.224e-02, with an active set of 200 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=9.602e-03, with an active set of 200 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=8.717e-03, with an active set of 200 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=8.447e-03, with an active set of 201 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=8.150e-03, with an active set of 201 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=7.825e-03, with an active set of 201 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=6.572e-03, with an active set of 202 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=3.497e-03, with an active set of 202 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=2.970e-03, with an active set of 202 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=2.481e-03, with an active set of 202 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=2.180e-03, with an active set of 202 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.952e-03, with an active set of 202 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.890e-03, with an active set of 202 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.878e-03, with an active set of 202 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.215e-03, with an active set of 202 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=8.593e-04, with an active set of 202 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=8.302e-04, with an active set of 202 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=6.829e-04, with an active set of 202 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=6.675e-04, with an active set of 202 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=4.726e-04, with an active set of 202 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=3.422e-04, with an active set of 202 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=3.151e-04, with an active set of 202 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=1.025e-04, with an active set of 202 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=5.493e-05, with an active set of 134 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=7.028e+01, with an active set of 168 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=6.625e+01, with an active set of 173 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=5.995e+01, with an active set of 183 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=5.778e+01, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=5.633e+01, with an active set of 188 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=2.521e+29, with an active set of 200 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=2.379e+29, with an active set of 200 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=1.985e+29, with an active set of 200 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=1.894e+29, with an active set of 201 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=1.745e+29, with an active set of 201 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=1.532e+29, with an active set of 201 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=1.179e+29, with an active set of 201 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=1.117e+29, with an active set of 201 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=1.015e+29, with an active set of 201 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=9.280e+28, with an active set of 202 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=7.514e+28, with an active set of 203 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=7.471e+28, with an active set of 203 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=6.683e+28, with an active set of 203 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=5.608e+28, with an active set of 203 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=5.034e+28, with an active set of 203 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=4.751e+28, with an active set of 203 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=4.239e+28, with an active set of 203 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=3.727e+28, with an active set of 203 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=5.414e+28, with an active set of 204 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=5.326e+28, with an active set of 204 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=4.072e+28, with an active set of 204 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=3.956e+28, with an active set of 204 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=3.562e+28, with an active set of 204 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=3.503e+28, with an active set of 204 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.868e+28, with an active set of 204 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.797e+28, with an active set of 204 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.498e+28, with an active set of 204 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.330e+28, with an active set of 204 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=1.799e+28, with an active set of 204 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=1.403e+28, with an active set of 205 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=1.076e+28, with an active set of 205 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=7.178e+27, with an active set of 205 regressors, and the smallest cholesky pivot element being 8.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=7.078e+27, with an active set of 205 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=4.887e+27, with an active set of 205 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=4.824e+27, with an active set of 205 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=4.371e+27, with an active set of 205 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=4.003e+27, with an active set of 205 regressors, and the smallest cholesky pivot element being 8.093e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=3.197e+27, with an active set of 205 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=3.077e+27, with an active set of 205 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=2.489e+27, with an active set of 205 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=2.017e+27, with an active set of 205 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=1.413e+27, with an active set of 205 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=1.180e+27, with an active set of 205 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=1.946e+00, with an active set of 172 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=1.491e+00, with an active set of 177 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=1.409e+00, with an active set of 181 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=1.577e+00, with an active set of 186 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=1.564e+00, with an active set of 187 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=2.247e+01, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=3.735e+01, with an active set of 196 regressors, and the smallest cholesky pivot element being 8.816e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 279 iterations, i.e. alpha=3.712e+01, with an active set of 196 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 288 iterations, i.e. alpha=4.119e+01, with an active set of 200 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=5.505e+02, with an active set of 204 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 305 iterations, i.e. alpha=6.600e+02, with an active set of 205 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=6.693e+02, with an active set of 206 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=5.779e+02, with an active set of 206 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=5.049e+02, with an active set of 206 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=4.664e+02, with an active set of 206 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=4.109e+02, with an active set of 206 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=3.969e+02, with an active set of 206 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=3.431e+02, with an active set of 206 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=2.697e+02, with an active set of 206 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=2.403e+02, with an active set of 206 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=1.399e+02, with an active set of 206 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=6.188e+01, with an active set of 206 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=4.224e+01, with an active set of 206 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 450197681457837849283238316965804196732338176.0000 (900395362915675698566476633931608393464676352.0000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.Lars()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/lars_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.3992 (0.0159)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.Lasso()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/lasso_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.3992 (0.0159)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.LassoLars()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/lasso_lars_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 179 iterations, i.e. alpha=1.694e-05, with an active set of 165 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=5.989e-06, with an active set of 181 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 203 iterations, alpha=5.286e-06, previous alpha=5.196e-06, with an active set of 186 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 198 iterations, i.e. alpha=6.917e-06, with an active set of 184 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 199 iterations, i.e. alpha=6.864e-06, with an active set of 185 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 211 iterations, alpha=5.899e-06, previous alpha=3.077e-06, with an active set of 194 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=4.761e-05, with an active set of 130 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=4.761e-05, with an active set of 130 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=4.326e-05, with an active set of 135 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=3.985e-05, with an active set of 138 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=3.985e-05, with an active set of 138 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 147 iterations, alpha=3.983e-05, previous alpha=3.949e-05, with an active set of 140 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=3.913e-05, with an active set of 139 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=3.910e-05, with an active set of 140 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 151 iterations, alpha=3.910e-05, previous alpha=3.799e-05, with an active set of 140 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1349 (0.0179)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=4.978e-06, with an active set of 185 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=4.955e-06, with an active set of 186 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=2.478e-06, with an active set of 191 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=1.119e-06, with an active set of 195 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 224 iterations, alpha=1.119e-06, previous alpha=1.053e-06, with an active set of 195 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.LassoLarsIC()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/lasso_lars_ic_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in expm1\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1941518545800.3599 (1687708150828.3491)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.LinearRegression(normalize=True, n_jobs=-1)\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/linear_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.2017 (0.0527)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.PassiveAggressiveRegressor()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/par_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 4055611.7709 (8111223.2279)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.RANSACRegressor()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/ransac_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1311 (0.0154)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.Ridge()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/ridge_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1162244918620.1626 (403661872749.9680)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cenk/.virtualenvs/udacity/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.SGDRegressor()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/sgd_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.2238 (0.0924)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.TheilSenRegressor()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/theil_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1254 (0.0082)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingRegressor()\n",
    "clf = clf.fit(tr_X, tr_y)\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/gradient_boosting_%s.csv\" %time.time(), index=False)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1240 (0.0165)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "\n",
    "score = rmsle_cv(ENet, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1262 (0.0127)\n"
     ]
    }
   ],
   "source": [
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "\n",
    "score = rmsle_cv(KRR, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1240 (0.0165)\n"
     ]
    }
   ],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "\n",
    "score = rmsle_cv(lasso, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1248 (0.0130)\n"
     ]
    }
   ],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "score = rmsle_cv(GBoost, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0796922170484\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "stacked_averaged_models.fit(tr_X, tr_y)\n",
    "tr_pred = stacked_averaged_models.predict(tr_X)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(te_X))\n",
    "\n",
    "print(rmsle(tr_y, tr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1216 (0.0088)\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "model_xgb.fit(tr_X, tr_y)\n",
    "xgb_pred = np.expm1(model_xgb.predict(te_X))\n",
    "\n",
    "score = rmsle_cv(model_xgb, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1247 (0.0101)\n"
     ]
    }
   ],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "model_lgb.fit(tr_X, tr_y)\n",
    "lgb_pred = np.expm1(model_lgb.predict(te_X))\n",
    "\n",
    "score = rmsle_cv(model_lgb, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = stacked_pred*0.7 + xgb_pred*0.15 + lgb_pred*0.15\n",
    "sub = pd.DataFrame()\n",
    "sub['Id'] = te_id\n",
    "sub['SalePrice'] = ensemble\n",
    "sub.to_csv('results/ensemble.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.2705 (0.0106)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.keras.python.keras.layers import Dense\n",
    "from tensorflow.contrib.keras.python.keras.models import Sequential\n",
    "from tensorflow.contrib.keras.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "def create_model():\n",
    "    global input_dim\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(input_dim / 2), input_dim=input_dim, kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(int(input_dim / 4), kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(int(input_dim / 8), kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "input_dim = tr_X.shape[1]\n",
    "\n",
    "clf = KerasRegressor(build_fn=create_model, epochs=100, batch_size=5, verbose=0)\n",
    "clf.fit(tr_X, tr_y)\n",
    "\n",
    "score = rmsle_cv(clf, tr_X, tr_y)\n",
    "print(\"Score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "\n",
    "te_y = np.expm1(clf.predict(te_X))\n",
    "res = pd.DataFrame({\"Id\": te_id, \"SalePrice\": te_y.reshape(te_y.shape[0])})\n",
    "res.to_csv(\"results/dnn_regression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
